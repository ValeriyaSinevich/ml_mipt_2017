{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# CIFAR Conv Net\n",
    "\n",
    "И так, в этом ноутбуке Вы сделаете превую в своей жизни сверточную сеть! На сложном датасете. Cкачайте его кстати, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100  162M  100  162M    0     0  1905k      0  0:01:27  0:01:27 --:--:-- 4158kk      0  0:03:30  0:00:13  0:03:17  770k\n",
      "cifar-10-batches-py/\n",
      "cifar-10-batches-py/data_batch_4\n",
      "cifar-10-batches-py/readme.html\n",
      "cifar-10-batches-py/test_batch\n",
      "cifar-10-batches-py/data_batch_3\n",
      "cifar-10-batches-py/batches.meta\n",
      "cifar-10-batches-py/data_batch_2\n",
      "cifar-10-batches-py/data_batch_5\n",
      "cifar-10-batches-py/data_batch_1\n"
     ]
    }
   ],
   "source": [
    "!mkdir cifar10\n",
    "!curl -o cifar-10-python.tar.gz https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
    "!tar -xvzf cifar-10-python.tar.gz -C cifar10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named cuda",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-1153fdca9273>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/home/ec2-user/papers/preactivation_and_wide_resnet/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/valeriyasin/Documents/Python Scripts/ml/hw6/models.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mlasagne\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mInputLayer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMaxPool2DLayer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDenseLayer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDropoutLayer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhelper\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_norm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBatchNormLayer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# for ResNet\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mlasagne\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdnn\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mConv2DDNNLayer\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mConvLayer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mlasagne\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPool2DLayer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mElemwiseSumLayer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNonlinearityLayer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPadLayer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mGlobalPoolLayer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExpressionLayer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mlasagne\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mOrthogonal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mHeNormal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mGlorotNormal\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/lasagne/layers/dnn.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtheano\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtheano\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msandbox\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdnn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0minit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnonlinearities\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: No module named cuda"
     ]
    }
   ],
   "source": [
    "sys.path.append('/home/ec2-user/papers/preactivation_and_wide_resnet/')\n",
    "import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from cifar import load_CIFAR10\n",
    "plt.rcParams['figure.figsize'] = (10.0, 8.0) \n",
    "\n",
    "cifar10_dir = './cifar10/cifar-10-batches-py'\n",
    "X_train, y_train, X_test, y_test = load_CIFAR10(cifar10_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    mean_std = np.load(os.path.join(os.getcwd(), 'cifar-10-mean_std.npz'))\n",
    "    mean = mean_std['mean']\n",
    "    std = mean_std['std']\n",
    "except IOError:\n",
    "    mean = (X_train.mean(axis=(0, 2, 3), keepdims=True).astype(np.float32) +\\\n",
    "        X_test.mean(axis=(0, 2, 3), keepdims=True).astype(np.float32)) / 2 \n",
    "    std = np.concatenate((X_train, X_test)).std(axis=(0, 2, 3), keepdims=True).astype(np.float32)\n",
    "    np.savez(os.path.join(os.getcwd(), 'cifar-10-mean_std.npz'),\n",
    "             mean=mean, std=std)\n",
    "X_train = (X_train - mean) / std\n",
    "X_test = (X_test - mean) / std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "classes = ['plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "num_classes = len(classes)\n",
    "samples_per_class = 7\n",
    "for y, cls in enumerate(classes):\n",
    "    idxs = np.flatnonzero(y_train == y)\n",
    "    idxs = np.random.choice(idxs, samples_per_class, replace=False)\n",
    "    for i, idx in enumerate(idxs):\n",
    "        plt_idx = i * num_classes + y + 1\n",
    "        plt.subplot(samples_per_class, num_classes, plt_idx)\n",
    "        plt.imshow(X_train[idx].astype('uint8').transpose(1, 2, 0))\n",
    "        plt.axis('off')\n",
    "        if i == 0:\n",
    "            plt.title(cls)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import lasagne\n",
    "from theano import tensor as T\n",
    "from lasagne.nonlinearities import *\n",
    "\n",
    "input_X = T.tensor4(\"X\")\n",
    "target_y = T.vector(\"target Y integer\",dtype='int32')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "    # Соберите нейронку: \n",
    "- Many times x (Conv+Pool)\n",
    "- Many small convolutions like 3x3\n",
    "- Baetch Norm \n",
    "- Residual Connection\n",
    "- Data Augmentation \n",
    "- Learning rate Schedule \n",
    "- ...\n",
    "\n",
    "### Для вдохновения \n",
    "- http://torch.ch/blog/2015/07/30/cifar.html\n",
    "- http://www.robots.ox.ac.uk/~vgg/research/very_deep/\n",
    "- https://www.cs.unc.edu/~wliu/papers/GoogLeNet.pdf\n",
    "- https://github.com/szagoruyko/wide-residual-networks \n",
    "\n",
    "### Самое интересное\n",
    "- Для сдачи задания нужно набрать на точность тесте > **92.5**% (это займет много времени, торопитесь :) )\n",
    "- Для получения бонусных баллов > **95.0**%\n",
    "- Будет очень хорошо если вы придумаете свою архитектуру или сможете обучить что-то из вышеперечисленного :)\n",
    "- А для обучения всего этого добра вам будет куда удобнее использовать GPU на Amazon \n",
    "    - Инструкция https://github.com/persiyanov/ml-mipt/tree/master/amazon-howto \n",
    "    - Вам помогут tmux, CuDNN, ssh tunnel, nvidia-smi, ... \n",
    "    - Wish you get fun :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# net = lasagne.layers.InputLayer(shape=(None, 3, 32, 32), input_var=input_X)\n",
    "import models\n",
    "network = models.ResNet_FullPre_Wide(input_var=input_X)\n",
    "# import implemented2\n",
    "# network= Deep_Residual_Learning_CIFAR.build_cnn(input_var=input_X)\n",
    "# network = implemented2.create_v3(input_X, input_shape=(None, 3, 32, 32),ccp_num_filters=[64, 128, 128, 256],\n",
    "#                                  fc_num_units=[256, 256])\n",
    "# net = lasagne.layers.DenseLayer(net,num_units = 10, nonlinearity=softmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "output_train = lasagne.layers.get_output(network)\n",
    "output_test = lasagne.layers.get_output(network, deterministic=True)\n",
    "\n",
    "# set up the loss that we aim to minimize when using cat cross entropy our Y should be ints not one-hot\n",
    "loss = lasagne.objectives.categorical_crossentropy(output_train, Y)\n",
    "loss = loss.mean()\n",
    "\n",
    "# if using ResNet use L2 regularization\n",
    "all_layers = lasagne.layers.get_all_layers(output_layer)\n",
    "l2_penalty = lasagne.regularization.regularize_layer_params(all_layers, lasagne.regularization.l2) * 0.0001\n",
    "loss = loss + l2_penalty\n",
    "\n",
    "# set up loss functions for validation dataset\n",
    "test_loss = lasagne.objectives.categorical_crossentropy(output_test, Y)\n",
    "test_loss = test_loss.mean()\n",
    "\n",
    "test_acc = T.mean(T.eq(T.argmax(output_test, axis=1), Y), dtype=theano.config.floatX)\n",
    "\n",
    "# get parameters from network and set up sgd with nesterov momentum to update parameters, l_r is shared var so it can be changed\n",
    "l_r = theano.shared(np.array(LR_SCHEDULE[0], dtype=theano.config.floatX))\n",
    "params = lasagne.layers.get_all_params(output_layer, trainable=True)\n",
    "updates = nesterov_momentum(loss, params, learning_rate=l_r, momentum=0.9)\n",
    "#updates = adam(loss, params, learning_rate=l_r)\n",
    "\n",
    "# set up training and prediction functions\n",
    "train_fn = theano.function(inputs=[X,Y], outputs=loss, updates=updates, allow_input_downcast=True)\n",
    "valid_fn = theano.function(inputs=[X,Y], outputs=[test_loss, test_acc], allow_input_downcast=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Вот и всё, пошли её учить"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def iterate_minibatches(inputs, targets, batchsize, shuffle=False):\n",
    "    assert len(inputs) == len(targets)\n",
    "    if shuffle:\n",
    "        indices = np.arange(len(inputs))\n",
    "        np.random.shuffle(indices)\n",
    "    for start_idx in range(0, len(inputs) - batchsize + 1, batchsize):\n",
    "        if shuffle:\n",
    "            excerpt = indices[start_idx:start_idx + batchsize]\n",
    "        else:\n",
    "            excerpt = slice(start_idx, start_idx + batchsize)\n",
    "        yield inputs[excerpt], targets[excerpt]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def augment_minibatches(minibatches):\n",
    "    for inputs, targets in minibatches:\n",
    "        yield augment_batch(inputs), targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def augment_batch(X_batch, y_batch):  \n",
    "    trans_1 = random.randint(0, (PAD_CROP*2))\n",
    "    trans_2 = random.randint(0, (PAD_CROP*2))\n",
    "    crop_x1 = trans_1\n",
    "    crop_x2 = (PIXELS + trans_1)\n",
    "    crop_y1 = trans_2\n",
    "    crop_y2 = (PIXELS + trans_2)\n",
    "\n",
    "    # flip left-right choice\n",
    "    flip_lr = random.randint(0,1)\n",
    "\n",
    "    # set empty copy to hold augmented images so that we don't overwrite\n",
    "    X_batch_aug = np.copy(X_batch)\n",
    "\n",
    "    # for each image in the batch do the augmentation\n",
    "    for j in range(X_batch.shape[0]):\n",
    "        # for each image channel\n",
    "        for k in range(X_batch.shape[1]):\n",
    "            # pad and crop images\n",
    "            img_pad = np.pad(X_batch_aug[j,k], pad_width=((PAD_CROP,PAD_CROP), (PAD_CROP,PAD_CROP)), mode='constant')\n",
    "            X_batch_aug[j,k] = img_pad[crop_x1:crop_x2, crop_y1:crop_y2]\n",
    "\n",
    "            # flip left-right if chosen\n",
    "            if flip_lr == 1:\n",
    "                X_batch_aug[j,k] = np.fliplr(X_batch_aug[j,k])\n",
    "    return X_batch_aug, y_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import augment2\n",
    "aug1 = augment2.AddElementwise()\n",
    "aug2 = augment2.Fliplr()\n",
    "aug3  =augment2.Flipud()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def send(text):\n",
    "    import requests\n",
    "    requests.get(\"https://api.telegram.org/bot224136417:AAGJ2kKaoPiiksBVJ-8AslDTavFDL6btqqE/sendMessage?chat_id=153592892&text=%s\" % text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# learning_rate_var.set_value(lasagne.utils.floatX(learning_rate_var.get_value() * 0.01))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from models import ResNet_FullPre_Wide as ResNet\n",
    "#else:\n",
    "    #print 'Unsupported model %s'%variant\n",
    "\n",
    "# training params\n",
    "LR_SCHEDULE = {\n",
    "    0: 0.01,\n",
    "    10: 0.1,\n",
    "    80: 0.01,\n",
    "    120: 0.001,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Процесс обучения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "X_val = X_test\n",
    "y_val = y_test\n",
    "\n",
    "num_epochs = 200 #количество проходов по данным\n",
    "\n",
    "batch_size = 64 #размер мини-батча\n",
    "\n",
    "train_eval = []\n",
    "valid_eval = []\n",
    "valid_acc = []\n",
    "best_acc = 0.0\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    if epoch in LR_SCHEDULE:\n",
    "        l_r.set_value(LR_SCHEDULE[epoch])\n",
    "    # In each epoch, we do a full pass over the training data:\n",
    "    train_err = 0\n",
    "    train_acc = 0\n",
    "    train_batches = 0\n",
    "    start_time = time.time()\n",
    "\n",
    "    for batch in augment_minibatches(iterate_minibatches(X_train, y_train,batch_size)):\n",
    "        inputs, targets = batch\n",
    "        train_err_batch, train_acc_batch= train_fun(inputs, targets)\n",
    "        train_err += train_err_batch\n",
    "        train_acc += train_acc_batch\n",
    "        train_batches += 1\n",
    "        \n",
    "#     for batch in aug3.augment_batches(iterate_minibatches(X_train, y_train,batch_size)):\n",
    "#         inputs, targets = batch\n",
    "#         train_err_batch, train_acc_batch= train_fun(inputs, targets)\n",
    "#         train_err += train_err_batch\n",
    "#         train_acc += train_acc_batch\n",
    "#         train_batches += 1\n",
    "#     for batch in aug1.augment_batches(iterate_minibatches(X_train, y_train,batch_size)):\n",
    "#         inputs, targets = batch\n",
    "#         train_err_batch, train_acc_batch= train_fun(inputs, targets)\n",
    "#         train_err += train_err_batch\n",
    "#         train_acc += train_acc_batch\n",
    "#         train_batches += 1\n",
    "\n",
    "    val_acc = 0\n",
    "    val_batches = 0\n",
    "    for batch in iterate_minibatches(X_val, y_val, batch_size):\n",
    "        inputs, targets = batch\n",
    "        val_acc += accuracy_fun(inputs, targets)\n",
    "        val_batches += 1\n",
    "    if val_acc > best_acc:\n",
    "        best_acc = val_acc\n",
    "        best_params = lasagne.layers.get_all_param_values(network)\n",
    "\n",
    "    # Then we print the results for this epoch:\n",
    "    print(\"Epoch {} of {} took {:.3f}s\".format(epoch + 1, num_epochs, time.time() - start_time))\n",
    "    print(\"  training loss (in-iteration):\\t\\t{:.6f}\".format(train_err / train_batches))\n",
    "    print(\"  train accuracy:\\t\\t{:.2f} %\".format(train_acc / train_batches * 100))\n",
    "    print(\"  validation accuracy:\\t\\t{:.2f} %\".format(val_acc / val_batches * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final results:\n",
      "  test accuracy:\t\t0.9533 %\n",
      "Achievement unlocked: колдун 80 уровня\n"
     ]
    }
   ],
   "source": [
    "test_acc = 0\n",
    "test_batches = 0\n",
    "for batch in iterate_minibatches(X_test, y_test, 500):\n",
    "    inputs, targets = batch\n",
    "    acc = accuracy_fun(inputs, targets)\n",
    "    test_acc += acc\n",
    "    test_batches += 1\n",
    "print(\"Final results:\")\n",
    "print(\"  test accuracy:\\t\\t{:.4f} %\".format(\n",
    "    test_acc / test_batches * 100))\n",
    "\n",
    "if test_acc / test_batches * 100 > 80:\n",
    "    print \"Achievement unlocked: колдун 80 уровня\"\n",
    "else:\n",
    "    print \"Нужно больше магии!\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Заполните форму\n",
    "\n",
    "https://goo.gl/forms/EeadABISlVmdJqgr2 "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
